{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and soil moisture water balance function\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../../PixSWAB_V1')\n",
    "import calibration_tool.pixswab_v1_calibration_for_hyperOpt as pixswab\n",
    "import calibration_tool.hydroStats as hs\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "# import gc\n",
    "from csv import DictWriter\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "from hyperopt import hp\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixswab Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cleint for distributed computing for files larger than the memory capacity (RAM)\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "# import multiprocessing as mp\n",
    "# from dask.distributed import progress\n",
    "\n",
    "# # multiprocessing client\n",
    "# client = pixswab.start_multiprocessing()\n",
    "# client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the config file and prepare inputs\n",
    "config_path = r'..\\config_files\\pixswab_config.ini'\n",
    "pixswab_inputs, pixswab_parameters, log_file_path, out_dir, encoding_output, bsahpe = pixswab.prepare_inputs(config_path)\n",
    "\n",
    "# read observed ourflw (discharge)\n",
    "Qobs_file = r'..\\..\\Upper_Litani\\input\\observed_flow\\discharge_Upper_Litani_JoubJannine_beforeQaraoun.csv'\n",
    "Qobs=pd.read_csv(Qobs_file,sep=',',index_col=0)\n",
    "target_column = 'km3/month'\n",
    "Qobs = Qobs[target_column]\n",
    "Qobs.index = pd.to_datetime(Qobs.index)\n",
    "\n",
    "# Path of calibration result file\n",
    "cal_path = r'..\\..\\Upper_Litani\\calibration_results\\calibration.csv'\n",
    "def write_to_csv_results(new_row,cal_path):\n",
    "    with open(cal_path, 'a', newline='') as f_object:\n",
    "        # Pass the file object and a list of column names to DictWriter()\n",
    "        dictwriter_object = DictWriter(f_object, fieldnames=list(new_row.keys()))\n",
    "        # Pass the dictionary as an argument to the Writerow()\n",
    "        dictwriter_object.writerow(new_row)\n",
    "        # Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "WarmupDays = 0\n",
    "space = {\n",
    "    'baseFlowReces': hp.uniform('baseFlowReces',0.0,1.0),\n",
    "    'deepPerc': hp.uniform('deepPerc',0.0,1.0),\n",
    "    'rcExp':hp.uniform('rcExp',1, 5.),\n",
    "    }\n",
    "\n",
    "def f_nn(params):\n",
    "    \n",
    "    result = pixswab.run_pixswab(pixswab_inputs, params)\n",
    "    Qsim = pixswab.compute_discharge(result, bsahpe, out_dir, log_file_path)\n",
    "    Qsim_target_column = 'discharge'\n",
    "    Qsim = Qsim[Qsim_target_column]\n",
    "    Qsim = Qsim[Qsim.index.isin(Qobs.index)]\n",
    "    KGE = hs.KGE(s=Qsim, o=Qobs, warmup=WarmupDays)\n",
    "    NSE = hs.NS(s=Qsim, o=Qobs, warmup=WarmupDays)\n",
    "    rmse = hs.rmse(s=Qsim, o=Qobs, warmup=WarmupDays)\n",
    "    # print('KGE = {0}, NSE = {1}, rmse = {2}'.format(KGE, NSE, rmse))\n",
    "      \n",
    "    new_row = {\n",
    "            'algorithm_name':'hyperopt',\n",
    "            'KGE': KGE,\n",
    "            'NSE': NSE,\n",
    "            'rmse': rmse,\n",
    "            'baseFlowReces': params['baseFlowReces'], \n",
    "            'deepPerc': params['deepPerc'],\n",
    "            'rcExp' : params['rcExp']\n",
    "            }\n",
    "    write_to_csv_results(new_row,cal_path)\n",
    "    return {\n",
    "            # 'loss': error_results['kge']*-1,\n",
    "            'loss': KGE*-1,\n",
    "            'status': STATUS_OK,\n",
    "            'params': params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|██████████████▌                                | 31/100 [21:37<48:03, 41.80s/trial, best loss: -0.782664470596379]"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_error = trials.results[np.argmin([r['loss'] for r in trials.results])]['loss']\n",
    "best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "\n",
    "worst_error = trials.results[np.argmax([r['loss'] for r in trials.results])]['loss']\n",
    "worst_params = trials.results[np.argmax([r['loss'] for r in trials.results])]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8139443541372209"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_results = pd.read_csv(os.path.join(MAIN_DIR,'calibration/calibration.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_results.sort_values(by='kge',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_results[40:].sort_values(by='kge',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_results.sort_values(by='kge',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "28a38c5ebd5800cf63447921f43c164575198c8795e8f0ec168080a3b8efe32d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
